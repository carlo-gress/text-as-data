---
title: "Assignment 4 - Topic Modelling"
author: "Carlo Greß"
date: "2023-11-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 0. Dependencies 

```{r}
library(tidyverse)
library(quanteda)
library(manifestoR)
library(readr)
library(gridExtra)
```

# 1. Data acquisition, description, and preparation

Loading the data. I chose to work with the programs of all German parties that have been part of the German Bundestag after the Federal election 1998 and 2002. In 1998, and after 16 years, the governing coalition switched from a liberal-conservative (FDP and CDU/CSU) to a social democratic/green government (SPD/Grüne). My goal is to identify whether programmatic similarities from the respective manifestos of SPD and Grüne could potentially have predicted these transitions. For this purpose, my approach is three-fold: First, I will examine all manifestos that have been published shortly before the 1998 election to see what the dominant topics across all parties are. Second, I will take a closer look to the 1998 manifestos of SPD and Grüne to determine whether these two parties shared programmatic similarities that might explain their later collaboration in government. Lastly, I will also look at the 2002 SPD and Grüne manifestos in order to evaluate whether they might have set diverging focal points which could be a reason for the  lack of electoral success in the following election. 

I am directly accessing the API and loading the manifesto corpus by restricting the country to Germany and setting the time span accordingly. As a result, only the manifestos published prior to the the 1998 and 2002 Federal Elections in Germany are considered. 

Printing the my_corpus document already reveals that we are dealing with 10 distinct documents (here: 10 distinct party manifestos). This intuitively makes sense since there are five different parties that have been elected to the German Bundestag in 1998, and we are looking at two distinct elections, so there are two manifestos per party (== 10 in total).

```{r}
mp_setapikey("manifesto_apikey.txt")

my_corpus <- mp_corpus(countryname == "Germany" & edate > as.Date("1998-01-01") & edate < as.Date("2003-01-01"))

my_corpus
```

Let's double-check which parties and years are represented in our corpus: As we can see from the output, we indeed have five distinct parties (represented by party codes) and two unique points in time. The time codes are easy to interpret: All documents are either from September 1998 or September 2002. Since Federal Elections usually take place in September and we want to analyse exactly the elections in the given years, this seems appropriate. 
```{r}
unique(meta(my_corpus, "date"))
unique(meta(my_corpus, "party"))
```

The party codes do not make intuitive sense. Let's store them and then use the larger main data set in order to print the party names that are attached to these codes (these are by default not included when directly importing single documents via the API, hence we refer to the main data): 

```{r}
party_id <- as.numeric(unique(meta(my_corpus, "party")))

main <- mp_maindataset()

main %>% 
  select(party, partyname) %>% 
  filter(party %in% party_id) %>% 
  distinct()
```

As we can see, five distinct parties are included: The SPD, the FDP, the CDU/CSU, the PDS (now: Die Linke), and Bündnis90/Die Grünen. That matches our expectation!

As a last step before diving deeper into the analysis, let's briefly examine how many quasi-sentences there are in each of the 10 manifestos. For this purpose, I am looping over the whole my_corpus object, assign the number of lines to num_lines, and printing the result.  
```{r}
for (i in seq_along(my_corpus)) {
  doc <- my_corpus[[i]]
  num_lines <- length(unlist(strsplit(as.character(doc), "\n")))
  cat("Manifesto", i, "consists of", num_lines, "quasi-sentences\n")
}
```
As we can see, the length of the 10 manifestos ranges from 596 to 2354 quasi-sentences. In total, the entire corpus contains 14788 quasi-sentences.

Next, I am already transforming the preliminary corpus into a format that the `quanteda`-package can easily use. I am keeping all the meta information since we want to make conclusions based on distinct years and parties later on. I chose to already group by year here, because I couldn't figure out how to group for two variables (year and party) during preprocessing later. Printing the resulting objects reveals that the combined manifestos from 2002 contain more quasi-sentences than in 1998.

```{r}
# Each quasi-sentence as document 
quanteda_corpus <- my_corpus %>%
  as.data.frame(with.meta = TRUE) %>%
  corpus(docid_field = "manifesto_id", unique_docnames = F)

corpus1998 <- quanteda_corpus %>% corpus_subset(date == 199809)
corpus2002 <- quanteda_corpus %>% corpus_subset(date == 200209)

corpus1998
corpus2002
```

Before running the topic models, we will apply some preprocessing to the manifestos in order to draw more meaningful conclusions from the analysis. In the following code chunk, I am removing punctuation, numbers and German stopwords, as well as stemming the whole corpus. Furthermore, I am excluding rare words that appear 5 times max. as well as words that appear often, but do not add meaningful information, as for example the party names. This step is crucial for the later analysis: The topic model algorithm itself cannot assess any important information from word itself, but is only assessing importance based on the frequency of words. Hence, if we would not include the substantially irrelevant stopwords, our topics would most likely be composed from only stopwords. 

For removing stopwords, we will use quantedas build-in tokens_remove function. I noticed, however, that some stopwords are not removed using that function. Therefore, I downloaded an additional document containing over 500 German stopwords and additionally exlcuded these from the corpus. This document can be found here: https://countwordsfree.com/stopwords/german. Moreover, there are some words that are correctly not considered stopwords, but would still distort our analysis since they (a) appear very frequently across manifestos but similarly are (b) not substantially important for the latent topics. These words mostly include party abbreviations our parts of a party's name. I will remove these words manually in the next preprocessing steps. 

```{r}
additional_stopwords <- readLines("stop_words_german.txt")

preprocessing98 <- corpus1998 %>%
  tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern = stopwords("german")) %>%
  tokens_remove(pattern = additional_stopwords) %>% 
  tokens_wordstem(language = "de") %>%
  tokens_remove(c("bündnis", "bundnis","fdp", "f.d.p", "cdu", "csu", "spd", "pds", "grünen", "programm", "muß", "muss", "uns", "dass")) %>% 
  dfm() %>% 
  dfm_trim(min_termfreq = 5) %>% 
  dfm_group(party)

preprocessing98

preprocessing02 <- corpus2002 %>%
  tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern = stopwords("german")) %>%
  tokens_remove(pattern = additional_stopwords) %>% 
  tokens_wordstem(language = "de") %>%
  tokens_remove(c("bündnis", "bundnis", "fdp", "f.d.p", "cdu", "csu", "spd", "pds", "grünen", "programm", "muß", "muss", "uns", "dass")) %>% 
  dfm() %>% 
  dfm_trim(min_termfreq = 5) %>% 
  dfm_group(party)

preprocessing02
```

# 2. Research question

After the preprocessing steps, we can start the modelling part. As already outlined, I am looking at the major German parties prior to the Federal elections 1998 and 2002, with a special emphasis on SPD and Grüne, since these parties won the Federal election 1998 and therefore introduced a change in government after 16 years of a conservative-liberal government. Using a topic modelling approach, I want to evaluate (a) What were the most prevalent topics prior to the elections 1998 and 2002? and (b) Did the SPD and Grüne had a programmatic overlap that could potentially explain their collaboration after 1998?

# 3. Topic model development

In order to answer the previously stated research question, we are using Latent Dirichlet Allocation (LDA) in order to identify broader topics within the manifestos. After excluding words (tokens) that do not add substantial meaning to the manifestos, the LDA model groups words that appear often in close proximity to each other into topics. We can chose the number of topics that the model should identify (which makes that a hyperparameter). However, including too many topics will result in a less useful output, since quite intuitively, the number of topics a manifesto can include is naturally limited. Depending on the ideological stance and programmatic focal points of a party, the LDA model will identify different topics for different parties. Intuitively, the model might identify topics related to ecological considerations in case of a Green party, and topics centered around social considerations in case of a center-left party. 

I am running the LDA model for both years and try to identify the five most important topics. As already outlined, the number of topics the model is identifying is a hyperparameter and thus can be adjusted. I tried several values for k (5, 10, 15) and noticed that adding more than five topics does not add any more meaning, since topics then become increasingly similar. 

```{r}
library(topicmodels) 

lda98 <- LDA(preprocessing98, 5)
lda02 <- LDA(preprocessing02, 5)
```

This next chunk prints out the fie most important topics and its corresponding tokens.
```{r}
library(tidytext)

topic_words98 <- tidy(lda98, matrix="beta") %>% 
  group_by(topic) %>%
  slice_max(beta, n = 5) %>%
  ungroup() %>%
  arrange(topic, -beta) 

topic_words98

topic_words02 <- tidy(lda02, matrix="beta") %>% 
  group_by(topic) %>%
  slice_max(beta, n = 5) %>%
  ungroup() %>%
  arrange(topic, -beta) 

topic_words02
```
For a more intuitive visualization, the next plots shos the tokens of the mos prevalent five topics for both years and including all manifestos. 
```{r}
topic_plot98 <- topic_words98 %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() + 
  labs(title = "Topics in all Manifestos 1998") + 
  ylab(label = "") +
  theme_bw()

topic_plot98
```
```{r}
topic_plot02 <- topic_words02 %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() + 
  labs(title = "Topics in all Manifestos 2002") +
  theme_bw()

topic_plot02
```

As we can see from the output, the model successfully identified the 5 most important topics across all manifestos for both election years. In 1998, most topics included some notion of Europe, which makes sense considering the transformation processes within the EU during that time. In 2002, Europe still is a prevalent token, but also new tokens as ecological and society appear. However, the topics for both years are not as distinct and clear as I expected them to be. However this might be due to the fact that five parties with very distinct ideological preferences are included in the corpus. 

For evaluating the states research question, I will now preprocess and run LDA models for the SPD and Grüne for both election years (1998 and 2002). The code applies the same preprocessing steps as before, making sure that punctuation, stopwords and less frequent or meaningful words are not influencing the analysis. Additionally, the LDA algorithm is directly applied in the next chunk as well.

```{r}
spd98 <- corpus1998 %>%
  corpus_subset(party == 41320) %>% 
  tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern = stopwords("german")) %>%
  tokens_remove(pattern = additional_stopwords) %>% 
  tokens_wordstem(language = "de") %>%
  tokens_remove(c("bündnis", "bundnis", "fdp", "f.d.p", "cdu", "csu", "spd", "pds", "grünen", "programm", "muß", "muss", "uns", "dass")) %>% 
  dfm() %>% 
  dfm_trim(min_termfreq = 5) %>% 
    dfm_group(party)
  
spd02 <- corpus2002 %>%
  corpus_subset(party == 41320) %>% 
  tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern = stopwords("german")) %>%
  tokens_remove(pattern = additional_stopwords) %>% 
  tokens_wordstem(language = "de") %>%
  tokens_remove(c("bündnis", "bundnis","fdp", "f.d.p", "cdu", "csu", "spd", "pds", "grünen", "programm", "muß", "muss", "uns", "dass")) %>% 
  dfm() %>% 
  dfm_trim(min_termfreq = 5) %>% 
  dfm_group(party)
  
lda98_spd <- LDA(spd98, 5)
lda02_spd <- LDA(spd02, 5)


topic_words98_spd <- tidy(lda98_spd, matrix="beta") %>% 
  group_by(topic) %>%
  slice_max(beta, n = 5) %>%
  ungroup() %>%
  arrange(topic, -beta) 

topic_words02_spd <- tidy(lda02_spd, matrix="beta") %>% 
  group_by(topic) %>%
  slice_max(beta, n = 5) %>%
  ungroup() %>%
  arrange(topic, -beta) 
```

The next chunk only stores the plots for the SPD topics in 1998 and 2002 in separate objects. The output will be discussed later and in direct comparison to the topics of Grüne. 
```{r}
spd_98_plot <- topic_words98_spd %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() +
  labs(title = "SPD 1998") +
  ylab(label = "") +
  theme_bw()

spd_02_plot <- topic_words02_spd %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() +
  labs(title = "SPD 2002") +
  ylab(label = "") +
  theme_bw()
```

Here, we are applying all preprocessing steps to only the manifestos of Grüne in 1998 and 2002. 
```{r}
grüne98 <- corpus1998 %>%
  corpus_subset(party == 41113) %>% 
  tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern = stopwords("german")) %>%
    tokens_remove(pattern = additional_stopwords) %>% 
  tokens_wordstem(language = "de") %>%
  tokens_remove(c("bündnis", "bundnis", "fdp", "f.d.p", "cdu", "csu", "spd", "pds", "grünen","grun", "programm", "muß", "muss", "uns", "dass")) %>% 
  dfm() %>% 
  dfm_trim(min_termfreq = 5) %>% 
  dfm_group(party)
  
grüne02 <- corpus2002 %>%
  corpus_subset(party == 41113) %>% 
  tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern = stopwords("german")) %>%
  tokens_remove(pattern = additional_stopwords) %>% 
  tokens_wordstem(language = "de") %>%
  tokens_remove(c("bündnis", "bundnis","fdp", "f.d.p", "cdu", "csu", "spd", "pds", "grünen", "grun", "programm", "muß", "muss", "uns", "dass")) %>% 
  dfm() %>% 
  dfm_trim(min_termfreq = 5) %>% 
  dfm_group(party)
  
lda98_grüne <- LDA(grüne98, 5)
lda02_grüne <- LDA(grüne02, 5)


topic_words98_grüne <- tidy(lda98_grüne, matrix="beta") %>% 
  group_by(topic) %>%
  slice_max(beta, n = 5) %>%
  ungroup() %>%
  arrange(topic, -beta) 

topic_words02_grüne <- tidy(lda02_grüne, matrix="beta") %>% 
  group_by(topic) %>%
  slice_max(beta, n = 5) %>%
  ungroup() %>%
  arrange(topic, -beta) 
```

Again, storing the plots in two distinct objects: 
```{r}
grüne_98_plot <- topic_words98_grüne %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() +
  labs(title = "Grüne 1998") +
  ylab(label = "") +
  theme_bw()

grüne_02_plot <- topic_words02_grüne %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() +
  labs(title = "Grüne 2002") + 
  ylab(label = "") +
  theme_bw()
```

# 4. Topic Model Description

```{r}
grüne_98_plot
spd_98_plot
```
Looking at the output of the topic models that the LDA model produced for SPD and Grüne for their manifestos prior to the Federal election in 1998, we easily can see that there are some differences to the earlier model ooutput that considered all manifestos for 1998: Exemplarily, the Green manifestos appear to contain some focus on ecological (topic 3 and 4), social (topic 3 and 5) questions as well as considerations regarding Europe (1, 2, 5). The focus of the SPD's manifesto is seemingly more targeted on societal/social considerations (1, 3, 4, 5), but also includes Europe (1, 2, 3). In summary, the topic models generates quite similar topics for both parties, but also highlights some differences (ecological considerations only for Grüne, justice only for SPD). In comparison to the full 1998 model, the results on the party level are a bit more centered around the ideological focus of both parties. On the other hand, the topics still are quite repetitive. As an intermediate conclusion and with regard to the research question, the 1998 topic model for SPD and Grüne shows that there is some programmativ overlap between the topics for both parties. However, these results should not be overestimated, since the five topics are not mutually exclusive and it is hard to assess what focus they are actually depicting. 

```{r}
grüne_02_plot
spd_02_plot
```

# Alternative approach: STM

```{r}
library(stm)

stm_model<- convert(preprocessing98,
to = "stm", docvars = docvars(preprocessing98))

stm_object <- stm(documents = stm_model$documents,
vocab = stm_model$vocab,
data = stm_model$meta,
K = 10,
seed = 12345)
```
```{r}
plot(stm_object)
```


